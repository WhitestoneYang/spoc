{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BACE dataset\n",
    "\n",
    "An example of classfication task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "# -------------------------\n",
    "import os\n",
    "import sys\n",
    "current_path = os.getcwd()\n",
    "sys.path.append(current_path)\n",
    "sys.path.append(os.path.join(sys.path[0], \"..\"))\n",
    "from spoc.process import generate_descriptors\n",
    "\n",
    "# Parameters\n",
    "# ----------\n",
    "task_name = \"bace\"\n",
    "\n",
    "# Download dataset by using the linkage\n",
    "url = \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/bace.csv\"\n",
    "\n",
    "# Data folder\n",
    "data_file = \"../data/sample_data/bace.csv\"\n",
    "feature_file = \"./features/all_descriptor_set--bace.pkl.zip\"\n",
    "\n",
    "# SMILES column\n",
    "smiles_col = \"mol\"\n",
    "\n",
    "# If the test_mode=\"test\", then a small amount of data will be used for test.\n",
    "test_mode = \"production\"\n",
    "\n",
    "# Descriptor generation\n",
    "# ---------------------\n",
    "# The generated descriptors will be stored with *.pkl.zip format in ./features/\n",
    "generate_descriptors.load_data(\n",
    "    task_name, url, data_file, feature_file, smiles_col, test_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Descriptor screening\n",
    "Evaluate the performance of various descriptors by using random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "# -------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "current_path = os.getcwd()\n",
    "sys.path.append(current_path)\n",
    "sys.path.append(os.path.join(sys.path[0], \"..\"))\n",
    "from spoc.process import generate_dataset\n",
    "from spoc.model import rf\n",
    "\n",
    "import importlib\n",
    "importlib.reload(rf)\n",
    "\n",
    "# Parameters\n",
    "# ----------\n",
    "# Data folder\n",
    "data_file = \"../data/sample_data/bace.csv\"\n",
    "feature_file = \"./features/all_descriptor_set--bace.pkl.zip\"\n",
    "output_file = \"./output/rf_SF_opt--bace.csv\"\n",
    "\n",
    "# The data column of target y\n",
    "task_col = \"Class\"\n",
    "\n",
    "# The data column of SMILES\n",
    "smiles_col = \"mol\"\n",
    "\n",
    "# Data splitting mode, including:\n",
    "# RandomSplitter, ScaffoldSplitter, SingletaskStratifiedSplitter\n",
    "# The recommended splitting mode can be used by refering the published paper.\n",
    "split_mode = \"ScaffoldSplitter\"\n",
    "\n",
    "# Random seed.\n",
    "# In this case, 5 random seeds are generated by 5 repeated tests.\n",
    "rnds = range(0, 500, 100)\n",
    "\n",
    "# Random seed for model training.\n",
    "model_rnd = 42\n",
    "\n",
    "# Load descriptor set & dataset\n",
    "# -----------------------------\n",
    "# \n",
    "data_df, desc_set_df = generate_dataset.load_dataset(data_file, feature_file)\n",
    "print(f\"data_df.shape: {data_df.shape}\")\n",
    "print(f\"desc_set_df.shape: {desc_set_df.shape}\")\n",
    "\n",
    "# Model traning\n",
    "# Screening the performance of all descriptors\n",
    "#---------------------------------------------\n",
    "# Feature list\n",
    "feature_types = desc_set_df.columns\n",
    "print(f\"feature_types: {feature_types}\")\n",
    "\n",
    "# Random forest\n",
    "# Hyper parameters of classification task.\n",
    "n_estimators, criterion, max_features, max_depth = 100, 'gini', 'auto', None\n",
    "\n",
    "result = []\n",
    "for i, feat_type in enumerate(feature_types):\n",
    "\n",
    "    print(f\"{'-'*30}\")\n",
    "    print(f\"{i}th task: {feat_type}\")\n",
    "\n",
    "    roc_auc_test_list = []\n",
    "    for rnd in rnds:\n",
    "\n",
    "        # Read dataset\n",
    "        X_train, X_test, y_train, y_test = generate_dataset.single_descriptor(\n",
    "            data_df, desc_set_df, smiles_col, task_col, feat_type, split_mode=\"RandomSplitter\", frac_train=0.9, rnd=42)\n",
    "\n",
    "        # Model training\n",
    "        criteria = rf.rf_cls(X_train, X_test, y_train, y_test, n_estimators, criterion, max_features, max_depth, rnd=model_rnd)\n",
    "        \n",
    "        roc_auc_test = criteria['roc_auc_test']\n",
    "        roc_auc_test_list.append(roc_auc_test)\n",
    "\n",
    "    roc_auc_test_ave = round(np.average(roc_auc_test_list), 3)\n",
    "    roc_auc_test_std = round(np.std(roc_auc_test_list), 3)\n",
    "\n",
    "    result.append([feat_type, n_estimators, criterion, max_features, max_depth, str(\n",
    "        roc_auc_test_list), roc_auc_test_ave, roc_auc_test_std])\n",
    "\n",
    "df = pd.DataFrame(result, columns=['feat_type', 'n_estimators', 'criterion', 'max_features',\n",
    "                  'max_depth', 'roc_auc_test_list', 'roc_auc_test_ave', 'roc_auc_test_std'])\n",
    "# Save the results\n",
    "df.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. SPOC screening\n",
    "Evaluate the performance of various S+POC combination by using random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "# -------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "current_path = os.getcwd()\n",
    "sys.path.append(current_path)\n",
    "sys.path.append(os.path.join(sys.path[0], \"..\"))\n",
    "from spoc.process import generate_dataset\n",
    "from spoc.model import rf\n",
    "\n",
    "import importlib\n",
    "importlib.reload(generate_dataset)\n",
    "importlib.reload(rf)\n",
    "\n",
    "# Parameters\n",
    "# ----------\n",
    "# Data folder\n",
    "data_file = \"../data/sample_data/bace.csv\"\n",
    "feature_file = \"./features/all_descriptor_set--bace.pkl.zip\"\n",
    "rf_SF_opt_file = \"./output/rf_SF_opt--bace.csv\"\n",
    "output_file = \"./output/rf_SPOC_opt--bace.csv\"\n",
    "\n",
    "# target y value\n",
    "task_col = \"Class\"\n",
    "\n",
    "# SMILES column\n",
    "smiles_col = \"mol\"\n",
    "\n",
    "# Data splitting mode\n",
    "split_mode = \"ScaffoldSplitter\"\n",
    "\n",
    "# The criteria used for descriptor evaluation\n",
    "# For classification, roc_auc serves as the criteria\n",
    "criterion_col = \"roc_auc_test_ave\"\n",
    "\n",
    "# Performance sort order, bigger is better for roc_auc, so ascending=False  \n",
    "ascending = False\n",
    "\n",
    "# Random seed\n",
    "rnds = range(0, 500, 100)\n",
    "\n",
    "# Model random seed\n",
    "model_rnd = 42\n",
    "\n",
    "# Load descriptor set & dataset\n",
    "# -----------------------------\n",
    "data_df, desc_set_df = generate_dataset.load_dataset(data_file, feature_file)\n",
    "print(f\"data_df.shape: {data_df.shape}\")\n",
    "print(f\"desc_set_df.shape: {desc_set_df.shape}\")\n",
    "\n",
    "# 20 best S+POC combination\n",
    "# --------------------------\n",
    "# exclude ['Mordred','RDKitDescriptors']\n",
    "df = df[~df['feat_type'].isin(['Mordred', 'RDKitDescriptors'])]\n",
    "\n",
    "# ROC_AUC: bigger is better\n",
    "df = df.sort_values(by=[criterion_col], axis=0, ascending=ascending)\n",
    "\n",
    "# Choose the best 20 fingerprint\n",
    "df = df.iloc[:20, :]\n",
    "feature_type_Ss = df['feat_type'].values\n",
    "print(f\"20 best feature_Ss: {feature_type_Ss}\")\n",
    "feature_type_POCs = ['Mordred', 'RDKitDescriptors']\n",
    "print(f\"feature_POCs: {feature_type_POCs}\")\n",
    "\n",
    "# Model traning\n",
    "# Screening the performance of all descriptors\n",
    "#---------------------------------------------\n",
    "# Feature list\n",
    "feature_types = desc_set_df.columns\n",
    "print(f\"feature_types: {feature_types}\")\n",
    "\n",
    "# Random forest\n",
    "# Hyper parameters of classification\n",
    "n_estimators, criterion, max_features, max_depth = 100, 'gini', 'auto', None\n",
    "\n",
    "result = []\n",
    "for i, feat_type_S in enumerate(feature_type_Ss):\n",
    "    for j, feat_type_POC in enumerate(feature_type_POCs):\n",
    "        print(f\"{'-'*30}\")\n",
    "        print(f\"{i}th task: {feat_type}\")\n",
    "\n",
    "        roc_auc_test_list = []\n",
    "        for rnd in rnds:\n",
    "\n",
    "            # Load dataset\n",
    "            X_train, X_test, y_train, y_test = generate_dataset.SPOC_descriptor(\n",
    "                data_df, desc_set_df, smiles_col, task_col, feat_type_S, feat_type_POC, split_mode=\"RandomSplitter\", frac_train=0.9, rnd=42)\n",
    "\n",
    "            # Model training\n",
    "            criteria = rf.rf_cls(\n",
    "                X_train, X_test, y_train, y_test, n_estimators, criterion, max_features, max_depth, rnd=model_rnd)\n",
    "            roc_auc_test = criteria[\"roc_auc_test\"]\n",
    "            roc_auc_test_list.append(roc_auc_test)\n",
    "\n",
    "        roc_auc_test_ave = round(np.average(roc_auc_test_list), 3)\n",
    "        roc_auc_test_std = round(np.std(roc_auc_test_list), 3)\n",
    "\n",
    "        result.append([feat_type_S, feat_type_POC, n_estimators, criterion, max_features,\n",
    "                      max_depth, str(roc_auc_test_list), roc_auc_test_ave, roc_auc_test_std])\n",
    "\n",
    "df = pd.DataFrame(result, columns=['feat_type_S', 'feat_type_POC', 'n_estimators', 'criterion',\n",
    "                  'max_features', 'max_depth', 'roc_auc_test_list', 'roc_auc_test_ave', 'roc_auc_test_std'])\n",
    "\n",
    "# Save the results\n",
    "df.to_csv(output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Bayes Optimization by using LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "# -------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "current_path = os.getcwd()\n",
    "sys.path.append(current_path)\n",
    "sys.path.append(os.path.join(sys.path[0], \"..\"))\n",
    "from spoc.model import rf, lightgbm\n",
    "from spoc.process import generate_dataset\n",
    "\n",
    "import importlib\n",
    "importlib.reload(generate_dataset)\n",
    "importlib.reload(lightgbm)\n",
    "\n",
    "# Parameters\n",
    "# ----------\n",
    "# Data folder\n",
    "data_file = \"../data/sample_data/bace.csv\"\n",
    "feature_file = \"./features/all_descriptor_set--bace.pkl.zip\"\n",
    "rf_SPOC_opt_file = \"./output/rf_SPOC_opt--bace.csv\"\n",
    "output_file = \"./output/lgb_SPOC_opt--bace.csv\"\n",
    "\n",
    "# target y value\n",
    "task_col = \"Class\"\n",
    "\n",
    "# SMILES column\n",
    "smiles_col = \"mol\"\n",
    "\n",
    "# Data splitting mode\n",
    "split_mode = \"ScaffoldSplitter\"\n",
    "\n",
    "# The criteria used for descriptor evaluation\n",
    "# In this case (classification), roc_auc serves as the criteria\n",
    "criterion_col = \"roc_auc_test_ave\"\n",
    "\n",
    "# Performance sort order, bigger is better for ROC_AUC, so ascending=False \n",
    "ascending = False\n",
    "\n",
    "# Random seed\n",
    "rnds = range(0, 500, 100)\n",
    "\n",
    "# Model random seed\n",
    "model_rnd = 42\n",
    "\n",
    "# Bayes Optimization\n",
    "# Initial iteration, more is better\n",
    "init_iter = 3\n",
    "\n",
    "# Optimization times, more is better\n",
    "n_iters = 5\n",
    "\n",
    "# Task type: classification or regression\n",
    "task_type = \"binary_classification\"\n",
    "\n",
    "# LightGBM score function\n",
    "feval, ascending = lightgbm.feval_value(criterion_col)\n",
    "\n",
    "# Load descriptor set & dataset\n",
    "# -----------------------------\n",
    "data_df, desc_set_df = generate_dataset.load_dataset(data_file, feature_file)\n",
    "print(f\"data_df.shape: {data_df.shape}\")\n",
    "print(f\"desc_set_df.shape: {desc_set_df.shape}\")\n",
    "\n",
    "# Best S+POC combination\n",
    "# --------------------------\n",
    "df = pd.read_csv(rf_SPOC_opt_file)\n",
    "df = df.sort_values(by=[criterion_col], axis=0, ascending=ascending)\n",
    "feat_type_S = df['feat_type_S'].values[0]\n",
    "feat_type_POC = df['feat_type_POC'].values[0]\n",
    "print(f\"Best S+POCs combination: {feat_type_S} + {feat_type_POC}\")\n",
    "\n",
    "# Start hyper opt:\n",
    "#------------------------------------------\n",
    "roc_auc_train_list, roc_auc_test_list = [], []\n",
    "result = []\n",
    "for seed in rnds:\n",
    "    # Load data\n",
    "    X_train, X_test, y_train, y_test = generate_dataset.SPOC_descriptor(data_df, desc_set_df, smiles_col, task_col, feat_type_S, feat_type_POC, split_mode, frac_train=0.9, rnd=42)\n",
    "\n",
    "    print(f\"X_train.shape: {X_train.shape}, X_test.shape: {X_test.shape}, y_train.shape: {y_train.shape}, y_test.shape: {y_test.shape}\")\n",
    "\n",
    "    # Optimization\n",
    "    best_params = lightgbm.bayesopt_lgb(X_train, y_train, init_iter, n_iters, feval, criterion_col, pds='default', random_state=model_rnd, seed=seed, task=\"binary_classification\")\n",
    "    print(best_params)\n",
    "\n",
    "    criteria = lightgbm.lgb_train(X_train, X_test, y_train, y_test, best_params, feval, seed=seed, task=task_type)\n",
    "    roc_auc_train =  criteria[\"roc_auc_train\"]\n",
    "    roc_auc_test =  criteria[\"roc_auc_test\"]\n",
    "    roc_auc_train_list.append(roc_auc_train)\n",
    "    roc_auc_test_list.append(roc_auc_test)\n",
    "\n",
    "    temp_result = [seed, roc_auc_train, roc_auc_test, best_params]\n",
    "    result.append(temp_result)\n",
    "\n",
    "# Summary\n",
    "roc_auc_train_ave = np.average(roc_auc_train_list)\n",
    "roc_auc_test_ave = np.average(roc_auc_test_list)\n",
    "roc_auc_train_std = np.std(roc_auc_train_list)\n",
    "roc_auc_test_std = np.std(roc_auc_test_list)\n",
    "\n",
    "result.append([\"ave\", roc_auc_train_ave, roc_auc_test_ave, \"--\"])\n",
    "result.append([\"std\", roc_auc_train_std, roc_auc_test_std, \"--\"])\n",
    "\n",
    "# Save results\n",
    "# --------------\n",
    "df = pd.DataFrame(result, columns=['entry', 'roc_auc_train_ave', 'roc_auc_test_ave', 'best-params'])\n",
    "df.to_csv(output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Bayes Optimization with XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "# -------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "current_path = os.getcwd()\n",
    "sys.path.append(current_path)\n",
    "sys.path.append(os.path.join(sys.path[0], \"..\"))\n",
    "from spoc.model import xgboost\n",
    "from spoc.process import generate_dataset\n",
    "\n",
    "import importlib\n",
    "importlib.reload(xgboost)\n",
    "importlib.reload(generate_dataset)\n",
    "\n",
    "# Parameters\n",
    "# ----------\n",
    "# Data folder\n",
    "data_file = \"../data/sample_data/bace.csv\"\n",
    "feature_file = \"./features/all_descriptor_set--bace.pkl.zip\"\n",
    "rf_SPOC_opt_file = \"./output/rf_SPOC_opt--bace.csv\"\n",
    "output_file = \"./output/xgb_SPOC_opt--bace.csv\"\n",
    "\n",
    "# target y value\n",
    "task_col = \"Class\"\n",
    "\n",
    "# SMILES column\n",
    "smiles_col = \"mol\"\n",
    "\n",
    "# Data splitting mode\n",
    "split_mode = \"ScaffoldSplitter\"\n",
    "\n",
    "# The criteria used for descriptor evaluation\n",
    "# In this case (classification), roc_auc serves as the criteria\n",
    "criterion_col = \"roc_auc_test_ave\"\n",
    "\n",
    "# Performance sort order, bigger is better for ROC_AUC, so ascending=False \n",
    "ascending = False\n",
    "\n",
    "# Random seed\n",
    "rnds = range(0, 500, 100)\n",
    "\n",
    "# Model random seed\n",
    "model_rnd = 42\n",
    "\n",
    "# Bayes Optimization\n",
    "# Initial iteration, more is better\n",
    "init_iter = 1\n",
    "\n",
    "# Optimization times, more is better\n",
    "n_iters = 1\n",
    "\n",
    "# Task type: classification or regression\n",
    "task_type = \"binary_classification\"\n",
    "\n",
    "# Load descriptor set & dataset\n",
    "# -----------------------------\n",
    "data_df, desc_set_df = generate_dataset.load_dataset(data_file, feature_file)\n",
    "data_df = data_df[:600]\n",
    "print(f\"data_df.shape: {data_df.shape}\")\n",
    "print(f\"desc_set_df.shape: {desc_set_df.shape}\")\n",
    "\n",
    "# Best S+POC combination\n",
    "# --------------------------\n",
    "df = pd.read_csv(rf_SPOC_opt_file)\n",
    "df = df.sort_values(by=[criterion_col], axis=0, ascending=ascending)\n",
    "feat_type_S = df['feat_type_S'].values[0]\n",
    "feat_type_POC = df['feat_type_POC'].values[0]\n",
    "print(f\"Best S+POCs combination: {feat_type_S} + {feat_type_POC}\")\n",
    "\n",
    "# XGBoost score function\n",
    "feval, ascending = xgboost.feval_value(criterion_col)\n",
    "\n",
    "# Start hyper opt:\n",
    "#------------------------------------------\n",
    "roc_auc_train_list, roc_auc_test_list = [], []\n",
    "result = []\n",
    "for seed in rnds:\n",
    "    # Load data\n",
    "    X_train, X_test, y_train, y_test = generate_dataset.SPOC_descriptor(data_df, desc_set_df, smiles_col, task_col, feat_type_S, feat_type_POC, split_mode, frac_train=0.9, rnd=42)\n",
    "\n",
    "    print(f\"X_train.shape: {X_train.shape}, X_test.shape: {X_test.shape}, y_train.shape: {y_train.shape}, y_test.shape: {y_test.shape}\")\n",
    "\n",
    "    # Optimization\n",
    "    best_params = xgboost.bayesion_opt_xgb(X_train, y_train, task_type, init_iter, n_iters, feval, criterion_col, pds='default', random_state=model_rnd, seed=seed)\n",
    "    print(best_params)\n",
    "\n",
    "    criteria = xgboost.xgb_train(X_train, X_test, y_train, y_test, task_type, best_params, feval)\n",
    "    roc_auc_train =  criteria[\"roc_auc_train\"]\n",
    "    roc_auc_test =  criteria[\"roc_auc_test\"]\n",
    "    roc_auc_train_list.append(roc_auc_train)\n",
    "    roc_auc_test_list.append(roc_auc_test)\n",
    "\n",
    "    temp_result = [seed, roc_auc_train, roc_auc_test, best_params]\n",
    "    result.append(temp_result)\n",
    "\n",
    "# Summary\n",
    "roc_auc_train_ave = np.average(roc_auc_train_list)\n",
    "roc_auc_test_ave = np.average(roc_auc_test_list)\n",
    "roc_auc_train_std = np.std(roc_auc_train_list)\n",
    "roc_auc_test_std = np.std(roc_auc_test_list)\n",
    "\n",
    "result.append([\"ave\", roc_auc_train_ave, roc_auc_test_ave, \"--\"])\n",
    "result.append([\"std\", roc_auc_train_std, roc_auc_test_std, \"--\"])\n",
    "\n",
    "# Save results\n",
    "# ------------\n",
    "df = pd.DataFrame(result, columns=['entry', 'roc_auc_train_ave', 'roc_auc_test_ave', 'best-params'])\n",
    "df.to_csv(output_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aca259d8db635bbece2563d70fe12758e12d137d320d6781211d92aa27885c42"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('rdkit21')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
